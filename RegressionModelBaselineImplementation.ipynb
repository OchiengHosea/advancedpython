{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn import datasets, linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_goog_sp500_data():\n",
    "    googFile = 'data/GOOG.csv'\n",
    "    spFile = 'data/GSPC.csv'\n",
    "    \n",
    "    goog = pd.read_csv(googFile, sep=\",\", usecols=[0,6], names=['Date', 'Goog'], header=0)\n",
    "    sp = pd.read_csv(spFile, sep=\",\", usecols=[0,6], names=['Date', 'SP500'], header=0)\n",
    "    goog['SP500'] = sp['SP500']\n",
    "    \n",
    "    # Format the date date object into a datetime\n",
    "    goog['Date'] = pd.to_datetime(goog['Date'], format='%Y/%m/%d')\n",
    "    \n",
    "    returns = goog[\n",
    "        [key for key in dict(goog.dtypes) if dict(goog.dtypes)[key] in ['float64', 'int64']]].pct_change()\n",
    "    print(returns)\n",
    "    xData = np.array(returns['SP500'][1:])\n",
    "    yData = np.array(returns['Goog'][1:])\n",
    "    return xData, yData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Goog     SP500\n",
      "0         NaN       NaN\n",
      "1   -0.266038 -0.137519\n",
      "2    0.157814 -0.139216\n",
      "3   -0.237414 -0.095379\n",
      "4    0.129524 -0.071716\n",
      "..        ...       ...\n",
      "116  0.231549  0.070092\n",
      "117  0.101180  0.093222\n",
      "118  0.924289  0.919525\n",
      "119 -0.579488 -0.518566\n",
      "120 -0.928284 -0.960255\n",
      "\n",
      "[121 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xData, yData = read_goog_sp500_data()\n",
    "googModel = linear_model.LinearRegression()\n",
    "googModel.fit(xData.reshape(-1, 1), yData.reshape(-1, 1))\n",
    "# print(googModel.coef_)\n",
    "# print(googModel.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 499 iteration:\n",
      "W: 1.035515\n",
      "b: 0.015565\n",
      "cost: 0.048299\n",
      "After 999 iteration:\n",
      "W: 1.035515\n",
      "b: 0.015565\n",
      "cost: 0.048299\n",
      "After 1499 iteration:\n",
      "W: 1.035515\n",
      "b: 0.015565\n",
      "cost: 0.048299\n",
      "After 1999 iteration:\n",
      "W: 1.035515\n",
      "b: 0.015565\n",
      "cost: 0.048299\n",
      "After 2499 iteration:\n",
      "W: 1.035515\n",
      "b: 0.015565\n",
      "cost: 0.048299\n",
      "After 2999 iteration:\n",
      "W: 1.035515\n",
      "b: 0.015565\n",
      "cost: 0.048299\n",
      "After 3499 iteration:\n",
      "W: 1.035515\n",
      "b: 0.015565\n",
      "cost: 0.048299\n",
      "After 3999 iteration:\n",
      "W: 1.035515\n",
      "b: 0.015565\n",
      "cost: 0.048299\n",
      "After 4499 iteration:\n",
      "W: 1.035515\n",
      "b: 0.015565\n",
      "cost: 0.048299\n",
      "After 4999 iteration:\n",
      "W: 1.035515\n",
      "b: 0.015565\n",
      "cost: 0.048299\n"
     ]
    }
   ],
   "source": [
    "W = tf.Variable(tf.zeros([1,1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "Wx = tf.matmul(x, W)\n",
    "\n",
    "y = Wx + b\n",
    "\n",
    "y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "cost = tf.reduce_mean(tf.square(y_ -y))\n",
    "\n",
    "# train_step_constant = tf.train.GradientDescentOptimizer(0.1).minimize(cost)\n",
    "# train_step_constant = tf.train.AdagradOptimizer(1).minimize(cost)\n",
    "train_step_constant = tf.train.FtrlOptimizer(1).minimize(cost)\n",
    "\n",
    "def trainWithOnePointPerEpoch(steps, train_step):\n",
    "    init = tf.global_variables_initializer()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for i in range(steps):\n",
    "            xs = np.array([[xData[i % len(yData)]]])\n",
    "            ys = np.array([[yData[i % len(yData)]]])\n",
    "            \n",
    "            feed = {x: xs, y_: ys}\n",
    "            # this is the elephant in the room\n",
    "            sess.run(train_step, feed_dict=feed)\n",
    "            \n",
    "            if (i + 1) % 1000 == 0:\n",
    "                print(\"After %d iteration:\" % i)\n",
    "                print(\"W: %f\" % sess.run(W))\n",
    "                print(\"b: %f\" % sess.run(b))\n",
    "                \n",
    "                print(\"cost: %f\" % sess.run(cost, feed_dict=feed))\n",
    "                \n",
    "\n",
    "dataset_size = len(xData)\n",
    "\n",
    "def trainWithMultiplePointsPerEpoch(steps, train_step, batch_size):\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        \n",
    "        for i in range(steps):\n",
    "            if dataset_size == batch_size:\n",
    "                batch_start_idx = 0\n",
    "            elif dataset_size < batch_size:\n",
    "                raise ValueError(\"dataset_size: %d, must be greater than batch_size: %d\" % (dataset_size, batch_size))\n",
    "            else:\n",
    "                batch_start_idx = (i * batch_size) % (dataset_size)\n",
    "            \n",
    "            batch_end_idx = batch_start_idx + batch_size\n",
    "            \n",
    "            batch_xs = xData[batch_start_idx : batch_end_idx]\n",
    "            batch_ys = yData[batch_start_idx : batch_end_idx]\n",
    "            \n",
    "            feed = {x: batch_xs.reshape(-1, 1), y_:batch_ys.reshape(-1, 1)}\n",
    "            \n",
    "            sess.run(train_step, feed_dict=feed)\n",
    "            \n",
    "            if (i + 1) % 500 == 0:\n",
    "                print(\"After %d iteration:\" % i)\n",
    "                print(\"W: %f\" % sess.run(W))\n",
    "                print(\"b: %f\" % sess.run(b))\n",
    "                \n",
    "                print(\"cost: %f\" % sess.run(cost, feed_dict=feed))\n",
    "                \n",
    "\n",
    "# trainWithOnePointPerEpoch(10000, train_step_constant)\n",
    "trainWithMultiplePointsPerEpoch(5000, train_step_constant, len(xData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple regression\n",
    "def read_xom_oil_nasdaq_data():\n",
    "    def readFile(filename):\n",
    "        data = pd.read_csv(filename, sep=\",\", usecols=[0, 7], name=['Date', 'Price'], header=0)\n",
    "        # sort the data in acscending orderof date\n",
    "        data['Date'] = pd.to_datetime(data['Date'], format='%Y-%m-%d')\n",
    "        \n",
    "        data = data.sort_values(['Date'], ascending=[True])\n",
    "        returns = data[[key for key in dict(data.dtypes) if dict(data.dtypes)[key] in ['float64', 'int64']]].pct_changes()\n",
    "        return np.array(returns['Price'])[1:]\n",
    "    \n",
    "    nasdaqData = readFile('data/GPSC.csv')\n",
    "    oilData = readFile('data/USO.csv')\n",
    "    xomData = readFile('data/XOM.csv')\n",
    "    \n",
    "    return (nasdaqData, oilData, xomData)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
